# Teste: como diferentes LLMs geram código Python?

A intenção deste repo é documentar um teste que eu fiz de geração de código usando diferentes LLMs (locais e cloud).

## Modelos testados:

`executado na ☁️`

1. OpenAI: gpt4o
2. OpenAI: gpt4o-mini
3. Anthropic: Sonnet3.5

`executado localmente com Ollama `

4. Meta: llama3.1:8b | 4.7gb
5. Google: gemma2 | 5.4gb
6. Alibaba: qwen2.5-coder | 4.7gb


## O que tem no Repo?
Você vai encontrar um .md com o prompt completo.
E cada script (.py) gerado por cada uma das LLMs.
